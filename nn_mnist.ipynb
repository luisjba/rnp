{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Handwritten digits\n",
    "\n",
    "A neural network that recognized MNIST handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from nn_mnist_model import MNISTModel, run_tensorboard\n",
    "%matplotlib inline\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:2.7.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:{}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNist model instantiation\n",
    "\n",
    "We have prepared a Python class to easily load and manage the MNIST dataset and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 17:57:46.016406: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-17 17:57:46.016509: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "mnist_model = MNISTModel(\n",
    "    epochs=200,\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MNIST dataset\n",
    "\n",
    "The data is downloaded from the keras dataset. The dependent variable (y_train ans Y_test) is transformed as One-hot\n",
    "representation of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples. Each sample is a flaten vector of 784 elements\n",
      "10000 test samples\n",
      "10 Labels are One-hot encodded as columns\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load data\n",
    "mnist_model.load_data()\n",
    "print(\"{} train samples. Each sample is a flaten vector of {} elements\".format(mnist_model.X_train.shape[0],mnist_model.X_train.shape[1] ))\n",
    "print(\"{} test samples\".format(mnist_model.X_test.shape[0]))\n",
    "print(\"{} Labels are One-hot encodded as columns\".format(mnist_model.Y_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print some sample images from the MNIST dataset\n",
    "\n",
    "The data is loaded  and splited in `(mnist_model.X_train, mnist_model.Y_train),` for model traning and \n",
    "`(mnist_model.X_test, mnist_model.Y_test)` for model validation.\n",
    "\n",
    "With the `mnist_model.get_sample_images()` function we can get a random sample of images from the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = mnist_model.get_sample_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "With no hidden layers, the model by default will be uilt with one Dense layer with 10 units, connected to the input layer (with shape of 784) and  `softmax` activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_layer (Dense)         (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model.\n",
    "mnist_model.build()\n",
    "# Summary of the model\n",
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cpmpile the Model\n",
    "\n",
    "By default, the optimizer is **SGD**, loss `categorical_crossentropy` and metrics `[accuracy]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model.\n",
    "mnist_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 17:59:07.682961: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-02-17 17:59:07.848911: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "464/469 [============================>.] - ETA: 0s - loss: 1.2721 - accuracy: 0.7013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 17:59:11.501211: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 4s 9ms/step - loss: 1.2681 - accuracy: 0.7023 - val_loss: 0.8102 - val_accuracy: 0.8292\n",
      "Epoch 2/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.7162 - accuracy: 0.8376 - val_loss: 0.6093 - val_accuracy: 0.8562\n",
      "Epoch 3/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5889 - accuracy: 0.8570 - val_loss: 0.5279 - val_accuracy: 0.8724\n",
      "Epoch 4/200\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.5274 - accuracy: 0.8676 - val_loss: 0.4822 - val_accuracy: 0.8796\n",
      "Epoch 5/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.4897 - accuracy: 0.8741 - val_loss: 0.4524 - val_accuracy: 0.8848\n",
      "Epoch 6/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4637 - accuracy: 0.8789 - val_loss: 0.4309 - val_accuracy: 0.8890\n",
      "Epoch 7/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4444 - accuracy: 0.8821 - val_loss: 0.4146 - val_accuracy: 0.8915\n",
      "Epoch 8/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4294 - accuracy: 0.8853 - val_loss: 0.4015 - val_accuracy: 0.8945\n",
      "Epoch 9/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4172 - accuracy: 0.8878 - val_loss: 0.3912 - val_accuracy: 0.8966\n",
      "Epoch 10/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4071 - accuracy: 0.8905 - val_loss: 0.3822 - val_accuracy: 0.8993\n",
      "Epoch 11/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3985 - accuracy: 0.8918 - val_loss: 0.3748 - val_accuracy: 0.8996\n",
      "Epoch 12/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3911 - accuracy: 0.8934 - val_loss: 0.3683 - val_accuracy: 0.9009\n",
      "Epoch 13/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3847 - accuracy: 0.8951 - val_loss: 0.3627 - val_accuracy: 0.9016\n",
      "Epoch 14/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3790 - accuracy: 0.8962 - val_loss: 0.3574 - val_accuracy: 0.9019\n",
      "Epoch 15/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3739 - accuracy: 0.8976 - val_loss: 0.3534 - val_accuracy: 0.9038\n",
      "Epoch 16/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3694 - accuracy: 0.8987 - val_loss: 0.3492 - val_accuracy: 0.9041\n",
      "Epoch 17/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3652 - accuracy: 0.8995 - val_loss: 0.3458 - val_accuracy: 0.9056\n",
      "Epoch 18/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3614 - accuracy: 0.9005 - val_loss: 0.3424 - val_accuracy: 0.9056\n",
      "Epoch 19/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3580 - accuracy: 0.9012 - val_loss: 0.3394 - val_accuracy: 0.9070\n",
      "Epoch 20/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3548 - accuracy: 0.9019 - val_loss: 0.3367 - val_accuracy: 0.9077\n",
      "Epoch 21/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3518 - accuracy: 0.9026 - val_loss: 0.3342 - val_accuracy: 0.9084\n",
      "Epoch 22/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3490 - accuracy: 0.9035 - val_loss: 0.3316 - val_accuracy: 0.9092\n",
      "Epoch 23/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3465 - accuracy: 0.9040 - val_loss: 0.3295 - val_accuracy: 0.9092\n",
      "Epoch 24/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3441 - accuracy: 0.9044 - val_loss: 0.3274 - val_accuracy: 0.9098\n",
      "Epoch 25/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3419 - accuracy: 0.9049 - val_loss: 0.3254 - val_accuracy: 0.9103\n",
      "Epoch 26/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3397 - accuracy: 0.9057 - val_loss: 0.3239 - val_accuracy: 0.9103\n",
      "Epoch 27/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3378 - accuracy: 0.9061 - val_loss: 0.3222 - val_accuracy: 0.9108\n",
      "Epoch 28/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3358 - accuracy: 0.9066 - val_loss: 0.3206 - val_accuracy: 0.9111\n",
      "Epoch 29/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3341 - accuracy: 0.9072 - val_loss: 0.3189 - val_accuracy: 0.9120\n",
      "Epoch 30/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3323 - accuracy: 0.9078 - val_loss: 0.3175 - val_accuracy: 0.9128\n",
      "Epoch 31/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3307 - accuracy: 0.9084 - val_loss: 0.3163 - val_accuracy: 0.9130\n",
      "Epoch 32/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3292 - accuracy: 0.9083 - val_loss: 0.3150 - val_accuracy: 0.9131\n",
      "Epoch 33/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3277 - accuracy: 0.9089 - val_loss: 0.3138 - val_accuracy: 0.9133\n",
      "Epoch 34/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3263 - accuracy: 0.9094 - val_loss: 0.3127 - val_accuracy: 0.9145\n",
      "Epoch 35/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3250 - accuracy: 0.9098 - val_loss: 0.3115 - val_accuracy: 0.9144\n",
      "Epoch 36/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3237 - accuracy: 0.9098 - val_loss: 0.3102 - val_accuracy: 0.9148\n",
      "Epoch 37/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.3225 - accuracy: 0.9104 - val_loss: 0.3093 - val_accuracy: 0.9142\n",
      "Epoch 38/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3213 - accuracy: 0.9107 - val_loss: 0.3083 - val_accuracy: 0.9151\n",
      "Epoch 39/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3202 - accuracy: 0.9108 - val_loss: 0.3074 - val_accuracy: 0.9156\n",
      "Epoch 40/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.3190 - accuracy: 0.9111 - val_loss: 0.3065 - val_accuracy: 0.9148\n",
      "Epoch 41/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3180 - accuracy: 0.9116 - val_loss: 0.3058 - val_accuracy: 0.9150\n",
      "Epoch 42/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3170 - accuracy: 0.9119 - val_loss: 0.3051 - val_accuracy: 0.9157\n",
      "Epoch 43/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3160 - accuracy: 0.9122 - val_loss: 0.3042 - val_accuracy: 0.9158\n",
      "Epoch 44/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3150 - accuracy: 0.9122 - val_loss: 0.3034 - val_accuracy: 0.9157\n",
      "Epoch 45/200\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.3141 - accuracy: 0.9124 - val_loss: 0.3026 - val_accuracy: 0.9163\n",
      "Epoch 46/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3132 - accuracy: 0.9125 - val_loss: 0.3019 - val_accuracy: 0.9162\n",
      "Epoch 47/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3123 - accuracy: 0.9129 - val_loss: 0.3014 - val_accuracy: 0.9161\n",
      "Epoch 48/200\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.3116 - accuracy: 0.9130 - val_loss: 0.3005 - val_accuracy: 0.9166\n",
      "Epoch 49/200\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.3108 - accuracy: 0.9135 - val_loss: 0.3001 - val_accuracy: 0.9168\n",
      "Epoch 50/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3099 - accuracy: 0.9136 - val_loss: 0.2995 - val_accuracy: 0.9165\n",
      "Epoch 51/200\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.3092 - accuracy: 0.9141 - val_loss: 0.2990 - val_accuracy: 0.9171\n",
      "Epoch 52/200\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.3084 - accuracy: 0.9142 - val_loss: 0.2980 - val_accuracy: 0.9173\n",
      "Epoch 53/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3077 - accuracy: 0.9144 - val_loss: 0.2978 - val_accuracy: 0.9179\n",
      "Epoch 54/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3070 - accuracy: 0.9146 - val_loss: 0.2972 - val_accuracy: 0.9173\n",
      "Epoch 55/200\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.3064 - accuracy: 0.9145 - val_loss: 0.2968 - val_accuracy: 0.9179\n",
      "Epoch 56/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3057 - accuracy: 0.9150 - val_loss: 0.2963 - val_accuracy: 0.9170\n",
      "Epoch 57/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3050 - accuracy: 0.9149 - val_loss: 0.2957 - val_accuracy: 0.9176\n",
      "Epoch 58/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3044 - accuracy: 0.9151 - val_loss: 0.2953 - val_accuracy: 0.9181\n",
      "Epoch 59/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3038 - accuracy: 0.9154 - val_loss: 0.2948 - val_accuracy: 0.9174\n",
      "Epoch 60/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3032 - accuracy: 0.9156 - val_loss: 0.2944 - val_accuracy: 0.9182\n",
      "Epoch 61/200\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3026 - accuracy: 0.9158 - val_loss: 0.2940 - val_accuracy: 0.9175\n",
      "Epoch 62/200\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.3021 - accuracy: 0.9160 - val_loss: 0.2933 - val_accuracy: 0.9177\n",
      "Epoch 63/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3015 - accuracy: 0.9162 - val_loss: 0.2929 - val_accuracy: 0.9179\n",
      "Epoch 64/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3010 - accuracy: 0.9161 - val_loss: 0.2928 - val_accuracy: 0.9180\n",
      "Epoch 65/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.3004 - accuracy: 0.9166 - val_loss: 0.2925 - val_accuracy: 0.9170\n",
      "Epoch 66/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2999 - accuracy: 0.9168 - val_loss: 0.2920 - val_accuracy: 0.9179\n",
      "Epoch 67/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2994 - accuracy: 0.9165 - val_loss: 0.2914 - val_accuracy: 0.9178\n",
      "Epoch 68/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2989 - accuracy: 0.9166 - val_loss: 0.2911 - val_accuracy: 0.9182\n",
      "Epoch 69/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2984 - accuracy: 0.9166 - val_loss: 0.2909 - val_accuracy: 0.9181\n",
      "Epoch 70/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2979 - accuracy: 0.9171 - val_loss: 0.2905 - val_accuracy: 0.9182\n",
      "Epoch 71/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2975 - accuracy: 0.9172 - val_loss: 0.2900 - val_accuracy: 0.9189\n",
      "Epoch 72/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2970 - accuracy: 0.9174 - val_loss: 0.2899 - val_accuracy: 0.9190\n",
      "Epoch 73/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2965 - accuracy: 0.9175 - val_loss: 0.2897 - val_accuracy: 0.9191\n",
      "Epoch 74/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2961 - accuracy: 0.9174 - val_loss: 0.2892 - val_accuracy: 0.9192\n",
      "Epoch 75/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2957 - accuracy: 0.9177 - val_loss: 0.2887 - val_accuracy: 0.9191\n",
      "Epoch 76/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2953 - accuracy: 0.9179 - val_loss: 0.2886 - val_accuracy: 0.9192\n",
      "Epoch 77/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2949 - accuracy: 0.9181 - val_loss: 0.2880 - val_accuracy: 0.9196\n",
      "Epoch 78/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2944 - accuracy: 0.9180 - val_loss: 0.2881 - val_accuracy: 0.9192\n",
      "Epoch 79/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2940 - accuracy: 0.9183 - val_loss: 0.2876 - val_accuracy: 0.9200\n",
      "Epoch 80/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2937 - accuracy: 0.9184 - val_loss: 0.2876 - val_accuracy: 0.9195\n",
      "Epoch 81/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2933 - accuracy: 0.9185 - val_loss: 0.2873 - val_accuracy: 0.9197\n",
      "Epoch 82/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2929 - accuracy: 0.9186 - val_loss: 0.2872 - val_accuracy: 0.9193\n",
      "Epoch 83/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2926 - accuracy: 0.9184 - val_loss: 0.2867 - val_accuracy: 0.9194\n",
      "Epoch 84/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2922 - accuracy: 0.9188 - val_loss: 0.2864 - val_accuracy: 0.9203\n",
      "Epoch 85/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2918 - accuracy: 0.9191 - val_loss: 0.2861 - val_accuracy: 0.9197\n",
      "Epoch 86/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2914 - accuracy: 0.9187 - val_loss: 0.2857 - val_accuracy: 0.9200\n",
      "Epoch 87/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2911 - accuracy: 0.9191 - val_loss: 0.2856 - val_accuracy: 0.9202\n",
      "Epoch 88/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2908 - accuracy: 0.9190 - val_loss: 0.2856 - val_accuracy: 0.9204\n",
      "Epoch 89/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2904 - accuracy: 0.9193 - val_loss: 0.2852 - val_accuracy: 0.9207\n",
      "Epoch 90/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2901 - accuracy: 0.9194 - val_loss: 0.2851 - val_accuracy: 0.9199\n",
      "Epoch 91/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2898 - accuracy: 0.9194 - val_loss: 0.2848 - val_accuracy: 0.9200\n",
      "Epoch 92/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2895 - accuracy: 0.9197 - val_loss: 0.2845 - val_accuracy: 0.9199\n",
      "Epoch 93/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2891 - accuracy: 0.9196 - val_loss: 0.2841 - val_accuracy: 0.9198\n",
      "Epoch 94/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2888 - accuracy: 0.9199 - val_loss: 0.2841 - val_accuracy: 0.9202\n",
      "Epoch 95/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2885 - accuracy: 0.9201 - val_loss: 0.2839 - val_accuracy: 0.9207\n",
      "Epoch 96/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2882 - accuracy: 0.9199 - val_loss: 0.2838 - val_accuracy: 0.9204\n",
      "Epoch 97/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2879 - accuracy: 0.9200 - val_loss: 0.2837 - val_accuracy: 0.9203\n",
      "Epoch 98/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2876 - accuracy: 0.9202 - val_loss: 0.2832 - val_accuracy: 0.9204\n",
      "Epoch 99/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2874 - accuracy: 0.9200 - val_loss: 0.2832 - val_accuracy: 0.9198\n",
      "Epoch 100/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2870 - accuracy: 0.9205 - val_loss: 0.2831 - val_accuracy: 0.9196\n",
      "Epoch 101/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2868 - accuracy: 0.9203 - val_loss: 0.2829 - val_accuracy: 0.9194\n",
      "Epoch 102/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2865 - accuracy: 0.9205 - val_loss: 0.2827 - val_accuracy: 0.9197\n",
      "Epoch 103/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2862 - accuracy: 0.9203 - val_loss: 0.2825 - val_accuracy: 0.9207\n",
      "Epoch 104/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2860 - accuracy: 0.9204 - val_loss: 0.2824 - val_accuracy: 0.9203\n",
      "Epoch 105/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2857 - accuracy: 0.9204 - val_loss: 0.2821 - val_accuracy: 0.9200\n",
      "Epoch 106/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2854 - accuracy: 0.9207 - val_loss: 0.2819 - val_accuracy: 0.9199\n",
      "Epoch 107/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2852 - accuracy: 0.9207 - val_loss: 0.2818 - val_accuracy: 0.9208\n",
      "Epoch 108/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2849 - accuracy: 0.9211 - val_loss: 0.2815 - val_accuracy: 0.9203\n",
      "Epoch 109/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2847 - accuracy: 0.9210 - val_loss: 0.2814 - val_accuracy: 0.9209\n",
      "Epoch 110/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2844 - accuracy: 0.9212 - val_loss: 0.2811 - val_accuracy: 0.9208\n",
      "Epoch 111/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2842 - accuracy: 0.9212 - val_loss: 0.2811 - val_accuracy: 0.9205\n",
      "Epoch 112/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2839 - accuracy: 0.9213 - val_loss: 0.2809 - val_accuracy: 0.9213\n",
      "Epoch 113/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2837 - accuracy: 0.9214 - val_loss: 0.2806 - val_accuracy: 0.9214\n",
      "Epoch 114/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2835 - accuracy: 0.9215 - val_loss: 0.2805 - val_accuracy: 0.9205\n",
      "Epoch 115/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2832 - accuracy: 0.9215 - val_loss: 0.2803 - val_accuracy: 0.9211\n",
      "Epoch 116/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2830 - accuracy: 0.9215 - val_loss: 0.2805 - val_accuracy: 0.9209\n",
      "Epoch 117/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2828 - accuracy: 0.9217 - val_loss: 0.2800 - val_accuracy: 0.9210\n",
      "Epoch 118/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2826 - accuracy: 0.9216 - val_loss: 0.2799 - val_accuracy: 0.9210\n",
      "Epoch 119/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2823 - accuracy: 0.9216 - val_loss: 0.2800 - val_accuracy: 0.9214\n",
      "Epoch 120/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.2821 - accuracy: 0.9218 - val_loss: 0.2797 - val_accuracy: 0.9207\n",
      "Epoch 121/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2819 - accuracy: 0.9217 - val_loss: 0.2796 - val_accuracy: 0.9209\n",
      "Epoch 122/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2817 - accuracy: 0.9219 - val_loss: 0.2796 - val_accuracy: 0.9216\n",
      "Epoch 123/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2814 - accuracy: 0.9216 - val_loss: 0.2796 - val_accuracy: 0.9213\n",
      "Epoch 124/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.2813 - accuracy: 0.9219 - val_loss: 0.2793 - val_accuracy: 0.9217\n",
      "Epoch 125/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.2810 - accuracy: 0.9221 - val_loss: 0.2791 - val_accuracy: 0.9211\n",
      "Epoch 126/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2809 - accuracy: 0.9220 - val_loss: 0.2790 - val_accuracy: 0.9217\n",
      "Epoch 127/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2807 - accuracy: 0.9221 - val_loss: 0.2788 - val_accuracy: 0.9211\n",
      "Epoch 128/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2805 - accuracy: 0.9220 - val_loss: 0.2788 - val_accuracy: 0.9214\n",
      "Epoch 129/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2803 - accuracy: 0.9225 - val_loss: 0.2786 - val_accuracy: 0.9219\n",
      "Epoch 130/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2801 - accuracy: 0.9223 - val_loss: 0.2787 - val_accuracy: 0.9219\n",
      "Epoch 131/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2799 - accuracy: 0.9227 - val_loss: 0.2785 - val_accuracy: 0.9215\n",
      "Epoch 132/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2797 - accuracy: 0.9227 - val_loss: 0.2782 - val_accuracy: 0.9221\n",
      "Epoch 133/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2795 - accuracy: 0.9223 - val_loss: 0.2782 - val_accuracy: 0.9220\n",
      "Epoch 134/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2793 - accuracy: 0.9226 - val_loss: 0.2781 - val_accuracy: 0.9216\n",
      "Epoch 135/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2791 - accuracy: 0.9227 - val_loss: 0.2781 - val_accuracy: 0.9219\n",
      "Epoch 136/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2789 - accuracy: 0.9230 - val_loss: 0.2778 - val_accuracy: 0.9216\n",
      "Epoch 137/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2787 - accuracy: 0.9230 - val_loss: 0.2778 - val_accuracy: 0.9219\n",
      "Epoch 138/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2786 - accuracy: 0.9228 - val_loss: 0.2777 - val_accuracy: 0.9218\n",
      "Epoch 139/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2784 - accuracy: 0.9230 - val_loss: 0.2776 - val_accuracy: 0.9221\n",
      "Epoch 140/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2782 - accuracy: 0.9229 - val_loss: 0.2776 - val_accuracy: 0.9218\n",
      "Epoch 141/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2780 - accuracy: 0.9233 - val_loss: 0.2773 - val_accuracy: 0.9223\n",
      "Epoch 142/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2779 - accuracy: 0.9229 - val_loss: 0.2772 - val_accuracy: 0.9222\n",
      "Epoch 143/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2777 - accuracy: 0.9232 - val_loss: 0.2772 - val_accuracy: 0.9221\n",
      "Epoch 144/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2775 - accuracy: 0.9231 - val_loss: 0.2770 - val_accuracy: 0.9220\n",
      "Epoch 145/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2774 - accuracy: 0.9232 - val_loss: 0.2769 - val_accuracy: 0.9222\n",
      "Epoch 146/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2772 - accuracy: 0.9232 - val_loss: 0.2770 - val_accuracy: 0.9221\n",
      "Epoch 147/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2770 - accuracy: 0.9231 - val_loss: 0.2767 - val_accuracy: 0.9217\n",
      "Epoch 148/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2768 - accuracy: 0.9232 - val_loss: 0.2766 - val_accuracy: 0.9223\n",
      "Epoch 149/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2767 - accuracy: 0.9234 - val_loss: 0.2765 - val_accuracy: 0.9219\n",
      "Epoch 150/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2765 - accuracy: 0.9233 - val_loss: 0.2763 - val_accuracy: 0.9222\n",
      "Epoch 151/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2764 - accuracy: 0.9237 - val_loss: 0.2764 - val_accuracy: 0.9222\n",
      "Epoch 152/200\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.2762 - accuracy: 0.9236 - val_loss: 0.2763 - val_accuracy: 0.9225\n",
      "Epoch 153/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2760 - accuracy: 0.9236 - val_loss: 0.2762 - val_accuracy: 0.9222\n",
      "Epoch 154/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2759 - accuracy: 0.9239 - val_loss: 0.2761 - val_accuracy: 0.9229\n",
      "Epoch 155/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2758 - accuracy: 0.9234 - val_loss: 0.2761 - val_accuracy: 0.9225\n",
      "Epoch 156/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2756 - accuracy: 0.9238 - val_loss: 0.2760 - val_accuracy: 0.9222\n",
      "Epoch 157/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2755 - accuracy: 0.9237 - val_loss: 0.2759 - val_accuracy: 0.9223\n",
      "Epoch 158/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2753 - accuracy: 0.9237 - val_loss: 0.2757 - val_accuracy: 0.9223\n",
      "Epoch 159/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2752 - accuracy: 0.9237 - val_loss: 0.2757 - val_accuracy: 0.9231\n",
      "Epoch 160/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2750 - accuracy: 0.9239 - val_loss: 0.2755 - val_accuracy: 0.9222\n",
      "Epoch 161/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2749 - accuracy: 0.9240 - val_loss: 0.2756 - val_accuracy: 0.9222\n",
      "Epoch 162/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2748 - accuracy: 0.9241 - val_loss: 0.2754 - val_accuracy: 0.9229\n",
      "Epoch 163/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2745 - accuracy: 0.9242 - val_loss: 0.2754 - val_accuracy: 0.9229\n",
      "Epoch 164/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2745 - accuracy: 0.9239 - val_loss: 0.2752 - val_accuracy: 0.9230\n",
      "Epoch 165/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2743 - accuracy: 0.9241 - val_loss: 0.2755 - val_accuracy: 0.9224\n",
      "Epoch 166/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2742 - accuracy: 0.9242 - val_loss: 0.2751 - val_accuracy: 0.9231\n",
      "Epoch 167/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2740 - accuracy: 0.9241 - val_loss: 0.2750 - val_accuracy: 0.9232\n",
      "Epoch 168/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2739 - accuracy: 0.9242 - val_loss: 0.2749 - val_accuracy: 0.9230\n",
      "Epoch 169/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2738 - accuracy: 0.9242 - val_loss: 0.2748 - val_accuracy: 0.9228\n",
      "Epoch 170/200\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.2736 - accuracy: 0.9243 - val_loss: 0.2750 - val_accuracy: 0.9230\n",
      "Epoch 171/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2735 - accuracy: 0.9244 - val_loss: 0.2748 - val_accuracy: 0.9233\n",
      "Epoch 172/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2734 - accuracy: 0.9246 - val_loss: 0.2746 - val_accuracy: 0.9229\n",
      "Epoch 173/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2732 - accuracy: 0.9246 - val_loss: 0.2746 - val_accuracy: 0.9233\n",
      "Epoch 174/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2731 - accuracy: 0.9245 - val_loss: 0.2746 - val_accuracy: 0.9225\n",
      "Epoch 175/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2730 - accuracy: 0.9245 - val_loss: 0.2744 - val_accuracy: 0.9228\n",
      "Epoch 176/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2728 - accuracy: 0.9246 - val_loss: 0.2744 - val_accuracy: 0.9234\n",
      "Epoch 177/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2727 - accuracy: 0.9245 - val_loss: 0.2744 - val_accuracy: 0.9231\n",
      "Epoch 178/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2726 - accuracy: 0.9248 - val_loss: 0.2742 - val_accuracy: 0.9228\n",
      "Epoch 179/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2724 - accuracy: 0.9248 - val_loss: 0.2746 - val_accuracy: 0.9227\n",
      "Epoch 180/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2723 - accuracy: 0.9250 - val_loss: 0.2742 - val_accuracy: 0.9225\n",
      "Epoch 181/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2722 - accuracy: 0.9246 - val_loss: 0.2742 - val_accuracy: 0.9232\n",
      "Epoch 182/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2721 - accuracy: 0.9249 - val_loss: 0.2741 - val_accuracy: 0.9231\n",
      "Epoch 183/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2720 - accuracy: 0.9251 - val_loss: 0.2739 - val_accuracy: 0.9227\n",
      "Epoch 184/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2719 - accuracy: 0.9248 - val_loss: 0.2740 - val_accuracy: 0.9232\n",
      "Epoch 185/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2717 - accuracy: 0.9250 - val_loss: 0.2738 - val_accuracy: 0.9228\n",
      "Epoch 186/200\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.2716 - accuracy: 0.9251 - val_loss: 0.2739 - val_accuracy: 0.9232\n",
      "Epoch 187/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2715 - accuracy: 0.9253 - val_loss: 0.2737 - val_accuracy: 0.9226\n",
      "Epoch 188/200\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.2714 - accuracy: 0.9250 - val_loss: 0.2735 - val_accuracy: 0.9234\n",
      "Epoch 189/200\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.2713 - accuracy: 0.9251 - val_loss: 0.2737 - val_accuracy: 0.9230\n",
      "Epoch 190/200\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.2711 - accuracy: 0.9252 - val_loss: 0.2736 - val_accuracy: 0.9224\n",
      "Epoch 191/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2710 - accuracy: 0.9252 - val_loss: 0.2735 - val_accuracy: 0.9227\n",
      "Epoch 192/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2709 - accuracy: 0.9252 - val_loss: 0.2735 - val_accuracy: 0.9225\n",
      "Epoch 193/200\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.2708 - accuracy: 0.9252 - val_loss: 0.2734 - val_accuracy: 0.9228\n",
      "Epoch 194/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2707 - accuracy: 0.9254 - val_loss: 0.2732 - val_accuracy: 0.9229\n",
      "Epoch 195/200\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.2706 - accuracy: 0.9254 - val_loss: 0.2731 - val_accuracy: 0.9230\n",
      "Epoch 196/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2705 - accuracy: 0.9253 - val_loss: 0.2731 - val_accuracy: 0.9228\n",
      "Epoch 197/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2704 - accuracy: 0.9256 - val_loss: 0.2731 - val_accuracy: 0.9234\n",
      "Epoch 198/200\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 0.2703 - accuracy: 0.9253 - val_loss: 0.2730 - val_accuracy: 0.9233\n",
      "Epoch 199/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2701 - accuracy: 0.9255 - val_loss: 0.2731 - val_accuracy: 0.9225\n",
      "Epoch 200/200\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2700 - accuracy: 0.9254 - val_loss: 0.2728 - val_accuracy: 0.9232\n"
     ]
    }
   ],
   "source": [
    "# Training the model.\n",
    "mnist_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2728 - accuracy: 0.9232\n",
      "Test accuracy: 0.9232000708580017\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "test_loss, test_acc = mnist_model.evaluate()\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 74730), started 0:00:28 ago. (Use '!kill 74730' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5ea0e971c2c23a0a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5ea0e971c2c23a0a\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "899be85650f4fd9fd1c61155ad1038b3bd3ce4f173c19491b42003eb0b61918c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf_m1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
