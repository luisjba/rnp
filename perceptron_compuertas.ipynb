{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd19047-2bab-4430-990a-520db5f76485",
   "metadata": {},
   "source": [
    "# Perceptron para compuerta lógica OR\n",
    "\n",
    "\n",
    "En terminos matemáticos, describimos una neurona $K$ con las siguientes ecuaciones\n",
    "\n",
    "\\begin{equation}\n",
    "\\upsilon_k = \\sum_{j=1}^{m} W_{kj} X_j\n",
    "\\end{equation}\n",
    "\n",
    "y\n",
    "\n",
    "\\begin{equation}\n",
    "y_k = L \\left( \\upsilon_k + b_k \\right)\n",
    "\\end{equation}\n",
    "\n",
    "Donde $X_1, X_2,...X_m$ son las señales de entrada $W_{k1}, W_{k2},...W_{km}$ son\n",
    "los pesos asociados a cada conexión a la neurona,  $b_k$ es el bias, $L()$ es la función \n",
    "de activación. El bias $b_k$ tiene un efecto de aplicar una transformación a la salida\n",
    "de $\\upsilon_k$ \n",
    "\n",
    "\\begin{equation}\n",
    "\\upsilon_k = \\upsilon_k + b_k\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98238d24-40a3-4386-a919-1d7f1c00978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14e4d4f3-bd3b-405d-9166-c0ef1b095124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones\n",
    "\n",
    "def activation_threshold(Z):\n",
    "    \"\"\"Threshold activation function\n",
    "    \"\"\"\n",
    "    result = np.zeros((Z.shape[0]),dtype=np.int32)\n",
    "    result[Z >= 0] = 1\n",
    "    #return 1 if Z >= 0 else 0\n",
    "    return result\n",
    "\n",
    "def activation_threshold2(z):\n",
    "    \"\"\"Threshold activation function\n",
    "    \"\"\"\n",
    "    return 1 if z >= 0 else 0\n",
    "\n",
    "def activation_linear_by_parts(Z):\n",
    "    \"\"\"Lineal by parts activation function\n",
    "    \"\"\"\n",
    "    result = np.zeros((Z.shape[0]))\n",
    "    result[Z >= 0.5] = 1\n",
    "    filter_mask = (Z < 0.5) & (Z > -0.5)\n",
    "    result[filter_mask] = Z[filter_mask]\n",
    "    return result\n",
    "\n",
    "def activation_sigmoid(Z):\n",
    "    \"\"\"Sigmoid activation function\n",
    "    \"\"\"\n",
    "    return 1 /(1 + np.exp(-Z))\n",
    "\n",
    "def gx(X:np.array, W:np.array):\n",
    "    \"\"\"Return the sum of X by W\"\"\"\n",
    "    # The not matricial implementation\n",
    "    # result_sum = 0\n",
    "    # for i in range(X.shape[0]):\n",
    "    #     result_sum += X[i] * W[i]\n",
    "    # return result_sum\n",
    "    # similar to np.dot(X,W.T)\n",
    "    return X @ W.T \n",
    "\n",
    "def forward(X:np.array, W:np.array):\n",
    "    \"\"\"Forward propagation \"\"\"\n",
    "    # Add the bias of 1's in column 0\n",
    "    Y = gx(X, W)\n",
    "    return Y\n",
    "\n",
    "def get_X_biased(X,W):\n",
    "    \"\"\"Check and return the X value with the bias value\"\"\"\n",
    "    if len(X.shape) == 1:\n",
    "        if len(X) < len(W):\n",
    "            X = np.hstack(([1], X))\n",
    "    elif X.shape[1] < len(W):\n",
    "            X = np.hstack((np.ones((X.shape[0],1)), X))\n",
    "    return X\n",
    "\n",
    "def predict(X,W,activation_fn = activation_threshold):\n",
    "    \"\"\"Predict values\"\"\"\n",
    "    # check if the bias need to be added\n",
    "    X = get_X_biased(X,W)\n",
    "    Z = forward(X, W)\n",
    "    return activation_fn(Z)\n",
    "\n",
    "def loss_fn(Y, Y_pred):\n",
    "    \"\"\"Loss function 1/2(Y-Y_pred)^2\"\"\"\n",
    "    y_diff = Y - Y_pred\n",
    "    return (y_diff * y_diff) / 2\n",
    "\n",
    "def backward(W:np.array, y:int, y_pred:int, x:np.array, lr=0.001) -> np.array:\n",
    "    \"\"\"Backward propagation\n",
    "    x = is a single vector of feature\n",
    "    lr = learning rate\n",
    "    return the new weights\n",
    "    \"\"\"\n",
    "    print(\"Valor esperado={}, obtenido={}\".format(y, y_pred))\n",
    "    for j in range(len(W)):\n",
    "        w_j = W[j]\n",
    "        W[j] = W[j] + lr * (y-y_pred) * x[j]\n",
    "        print(\"W{}={} -> {}, Y={}, Y'={}, x={}\".format(j,w_j,W[j],y,y_pred, x[j]))\n",
    "    return W\n",
    "\n",
    "def train(X,Y,W,lr=0.001,activation_fn = activation_threshold):\n",
    "    \"\"\"Trains ang graph results\"\"\"\n",
    "    X = get_X_biased(X,W)\n",
    "    max_iterations = 5 # this is to avoid infinite loop\n",
    "    iteration = 0\n",
    "    converged = False\n",
    "    while not converged and iteration <= max_iterations:\n",
    "        #Y_pred = predict(X,W,activation_fn)\n",
    "        # print(Y_pred)\n",
    "        # print(X)\n",
    "        total_loss = 0\n",
    "        for i in range(len(X)):\n",
    "            # print(W, Y[i], Y_pred[i], X[i])\n",
    "            y_pred = predict(X[i],W,activation_fn)\n",
    "            total_loss += loss_fn(Y, y_pred)\n",
    "            # print(backward(W, Y[i], y_pred, X[i], lr))\n",
    "            W = backward(W, Y[i], y_pred, X[i], lr)\n",
    "        iteration += 1\n",
    "        total_loss = total_loss.sum()\n",
    "        print(\"Iteration: {}, loss={}\".format(iteration, total_loss))\n",
    "        if total_loss == 0:\n",
    "            converged = True\n",
    "    print(\"Stoped at Iteration: {}, loss={}, converged={}\".format(iteration, total_loss,\"Yes\" if converged else \"NO\"))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f72649c-9c3b-44c5-a3a4-71ed3fd1583e",
   "metadata": {},
   "source": [
    "## Logica OR con Perceptron\n",
    "\n",
    "|$X_1$|$X_2$| $y$|\n",
    "|--|--|--|\n",
    "|0|0|0|\n",
    "|0|1|1|\n",
    "|1|0|1|\n",
    "|1|1|1|\n",
    "\n",
    "Hacemos el set de datos en las variables X y Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad23a23a-9575-411e-9b98-a1f2173a896d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd878403b20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_OR = np.array(\n",
    "    [\n",
    "        [0,0,0],\n",
    "        [0,1,1],\n",
    "        [1,0,1],\n",
    "        [1,1,1]\n",
    "    ]\n",
    "    ,dtype=np.int32)\n",
    "X = data_OR[:,:2]\n",
    "Y = data_OR[:,-1]\n",
    "plt.scatter(X[0], X[1], color = 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ebccc2-5974-424a-93f0-6934150ef9d2",
   "metadata": {},
   "source": [
    "Creamos los Weights para el perceptron, incluyendo el $W_0$ para el bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a13dc50-3227-4e91-8567-249a36ddf141",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.rand(X.shape[1] + 1)\n",
    "lr = 0.01\n",
    "activation_fn = activation_threshold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4698dfdd-8d84-4ebb-a98a-3aaa3cac0909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor esperado=0, obtenido=1\n",
      "W0=0.09245688624127718 -> 0.08245688624127719, Y=0, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=0, Y'=1, x=0.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=0, Y'=1, x=0.0\n",
      "Valor esperado=1, obtenido=1\n",
      "W0=0.08245688624127719 -> 0.08245688624127719, Y=1, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=1, Y'=1, x=0.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=1, Y'=1, x=1.0\n",
      "Valor esperado=1, obtenido=1\n",
      "W0=0.08245688624127719 -> 0.08245688624127719, Y=1, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=1, Y'=1, x=1.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=1, Y'=1, x=0.0\n",
      "Valor esperado=1, obtenido=1\n",
      "W0=0.08245688624127719 -> 0.08245688624127719, Y=1, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=1, Y'=1, x=1.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=1, Y'=1, x=1.0\n",
      "Iteration: 1, loss=2.0\n",
      "Valor esperado=0, obtenido=1\n",
      "W0=0.08245688624127719 -> 0.07245688624127719, Y=0, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=0, Y'=1, x=0.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=0, Y'=1, x=0.0\n",
      "Valor esperado=1, obtenido=1\n",
      "W0=0.07245688624127719 -> 0.07245688624127719, Y=1, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=1, Y'=1, x=0.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=1, Y'=1, x=1.0\n",
      "Valor esperado=1, obtenido=1\n",
      "W0=0.07245688624127719 -> 0.07245688624127719, Y=1, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=1, Y'=1, x=1.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=1, Y'=1, x=0.0\n",
      "Valor esperado=1, obtenido=1\n",
      "W0=0.07245688624127719 -> 0.07245688624127719, Y=1, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=1, Y'=1, x=1.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=1, Y'=1, x=1.0\n",
      "Iteration: 2, loss=2.0\n",
      "Valor esperado=0, obtenido=1\n",
      "W0=0.07245688624127719 -> 0.06245688624127719, Y=0, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=0, Y'=1, x=0.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=0, Y'=1, x=0.0\n",
      "Valor esperado=1, obtenido=1\n",
      "W0=0.06245688624127719 -> 0.06245688624127719, Y=1, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=1, Y'=1, x=0.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=1, Y'=1, x=1.0\n",
      "Valor esperado=1, obtenido=1\n",
      "W0=0.06245688624127719 -> 0.06245688624127719, Y=1, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=1, Y'=1, x=1.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=1, Y'=1, x=0.0\n",
      "Valor esperado=1, obtenido=1\n",
      "W0=0.06245688624127719 -> 0.06245688624127719, Y=1, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=1, Y'=1, x=1.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=1, Y'=1, x=1.0\n",
      "Iteration: 3, loss=2.0\n",
      "Valor esperado=0, obtenido=1\n",
      "W0=0.06245688624127719 -> 0.05245688624127719, Y=0, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=0, Y'=1, x=0.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=0, Y'=1, x=0.0\n",
      "Valor esperado=1, obtenido=1\n",
      "W0=0.05245688624127719 -> 0.05245688624127719, Y=1, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=1, Y'=1, x=0.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=1, Y'=1, x=1.0\n",
      "Valor esperado=1, obtenido=1\n",
      "W0=0.05245688624127719 -> 0.05245688624127719, Y=1, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=1, Y'=1, x=1.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=1, Y'=1, x=0.0\n",
      "Valor esperado=1, obtenido=1\n",
      "W0=0.05245688624127719 -> 0.05245688624127719, Y=1, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=1, Y'=1, x=1.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=1, Y'=1, x=1.0\n",
      "Iteration: 4, loss=2.0\n",
      "Valor esperado=0, obtenido=1\n",
      "W0=0.05245688624127719 -> 0.042456886241277185, Y=0, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=0, Y'=1, x=0.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=0, Y'=1, x=0.0\n",
      "Valor esperado=1, obtenido=1\n",
      "W0=0.042456886241277185 -> 0.042456886241277185, Y=1, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=1, Y'=1, x=0.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=1, Y'=1, x=1.0\n",
      "Valor esperado=1, obtenido=1\n",
      "W0=0.042456886241277185 -> 0.042456886241277185, Y=1, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=1, Y'=1, x=1.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=1, Y'=1, x=0.0\n",
      "Valor esperado=1, obtenido=1\n",
      "W0=0.042456886241277185 -> 0.042456886241277185, Y=1, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=1, Y'=1, x=1.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=1, Y'=1, x=1.0\n",
      "Iteration: 5, loss=2.0\n",
      "Valor esperado=0, obtenido=1\n",
      "W0=0.042456886241277185 -> 0.03245688624127718, Y=0, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=0, Y'=1, x=0.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=0, Y'=1, x=0.0\n",
      "Valor esperado=1, obtenido=1\n",
      "W0=0.03245688624127718 -> 0.03245688624127718, Y=1, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=1, Y'=1, x=0.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=1, Y'=1, x=1.0\n",
      "Valor esperado=1, obtenido=1\n",
      "W0=0.03245688624127718 -> 0.03245688624127718, Y=1, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=1, Y'=1, x=1.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=1, Y'=1, x=0.0\n",
      "Valor esperado=1, obtenido=1\n",
      "W0=0.03245688624127718 -> 0.03245688624127718, Y=1, Y'=1, x=1.0\n",
      "W1=0.7524484408442955 -> 0.7524484408442955, Y=1, Y'=1, x=1.0\n",
      "W2=0.6087730458058627 -> 0.6087730458058627, Y=1, Y'=1, x=1.0\n",
      "Iteration: 6, loss=2.0\n",
      "Stoped at Iteration: 6, loss=2.0, converged=NO\n"
     ]
    }
   ],
   "source": [
    "train(X, Y, W, lr=lr, activation_fn=activation_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b0089-036b-4193-8315-06496adf8b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ab5fc-6195-4d00-8641-d0a474f79ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e9eb34-ef28-405c-b5da-fab1d8d4ebea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6772a6e-99fe-4467-b59f-2e2057efe2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff587828-0362-442c-8049-6e32acb01d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bcb808-1400-4eae-9145-c9a00464937a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
